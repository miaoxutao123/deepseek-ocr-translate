#!/usr/bin/env python3
"""
æ¸…ç† OCR å†å²è®°å½•ä¸­çš„ DeepSeek-OCR åæ ‡æ ‡ç­¾

æ­¤è„šæœ¬ä¼šæ‰«ææ•°æ®åº“ä¸­æ‰€æœ‰å†å²è®°å½•ï¼Œæ¸…é™¤ OCR ç»“æœä¸­çš„åæ ‡æ ‡ç­¾ï¼Œ
ä¾‹å¦‚: text[[236, 255, 741, 325]]

ç”¨æ³•:
    python clean_ocr_tags.py              # é¢„è§ˆéœ€è¦æ¸…ç†çš„è®°å½•
    python clean_ocr_tags.py --apply      # å®é™…æ‰§è¡Œæ¸…ç†
    python clean_ocr_tags.py --backup     # æ‰§è¡Œæ¸…ç†å¹¶å¤‡ä»½æ•°æ®åº“
"""

import sys
import os
import re
import json
import shutil
from datetime import datetime
from pathlib import Path

# æ·»åŠ  app ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.models.history import History, TaskType
from app.config import settings


def clean_deepseek_tags(text: str) -> tuple[str, int]:
    """
    æ¸…ç†æ–‡æœ¬ä¸­çš„ DeepSeek-OCR æ ‡ç­¾

    Returns:
        (æ¸…ç†åçš„æ–‡æœ¬, æ¸…ç†çš„å­—ç¬¦æ•°)
    """
    if not text:
        return text, 0

    original_length = len(text)

    # Remove complete tag pairs: <|ref|>...<|/ref|><|det|>...<|/det|>
    text = re.sub(r'<\|ref\|>.*?<\/\|ref\|><\|det\|>.*?<\/\|det\|>\s*', '', text)

    # Remove standalone coordinate arrays like: text[[x, y, w, h]]
    text = re.sub(r'\[\[\d+,\s*\d+,\s*\d+,\s*\d+\]\]', '', text)

    # Remove any remaining special tokens like <|grounding|>, <|ref|>, <|/ref|>, etc.
    text = re.sub(r'<\|[^|]+\|>', '', text)

    # Remove content type labels (title, sub_title, text, image, etc.)
    # Pattern: word at start of line followed by newline
    text = re.sub(r'^(title|sub_title|text|image|caption|header|footer|table|figure)\s*\n', '', text, flags=re.MULTILINE)

    # Clean up multiple consecutive newlines
    text = re.sub(r'\n{3,}', '\n\n', text)

    cleaned_length = len(text)
    removed_chars = original_length - cleaned_length

    return text, removed_chars


def backup_database(db_path: str) -> str:
    """å¤‡ä»½æ•°æ®åº“"""
    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return None

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"{db_path}.backup_{timestamp}"

    try:
        shutil.copy2(db_path, backup_path)
        print(f"âœ… æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
        return backup_path
    except Exception as e:
        print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
        return None


def preview_cleaning(session):
    """é¢„è§ˆéœ€è¦æ¸…ç†çš„è®°å½•"""
    print("\n" + "=" * 60)
    print("é¢„è§ˆæ¨¡å¼ - æ‰«æéœ€è¦æ¸…ç†çš„è®°å½•")
    print("=" * 60 + "\n")

    # æŸ¥è¯¢æ‰€æœ‰æœ‰ OCR ç»“æœçš„è®°å½•
    histories = session.query(History).filter(
        History.ocr_result.isnot(None),
        History.ocr_result != ""
    ).all()

    total_records = 0
    total_removed = 0
    records_to_clean = []

    for history in histories:
        try:
            ocr_data = json.loads(history.ocr_result)

            # æ£€æŸ¥æ¯ä¸ªé¡µé¢çš„æ–‡æœ¬
            needs_cleaning = False
            total_page_removed = 0

            for page in ocr_data:
                if 'text' in page:
                    cleaned_text, removed = clean_deepseek_tags(page['text'])
                    if removed > 0:
                        needs_cleaning = True
                        total_page_removed += removed

            if needs_cleaning:
                total_records += 1
                total_removed += total_page_removed
                records_to_clean.append({
                    'id': history.id,
                    'filename': history.original_filename,
                    'pages': len(ocr_data),
                    'removed': total_page_removed
                })

        except json.JSONDecodeError:
            continue

    # æ˜¾ç¤ºç»“æœ
    if total_records == 0:
        print("âœ… æœªå‘ç°éœ€è¦æ¸…ç†çš„è®°å½•\n")
        return False

    print(f"ğŸ“Š å‘ç° {total_records} æ¡è®°å½•éœ€è¦æ¸…ç†:\n")

    for record in records_to_clean[:10]:  # åªæ˜¾ç¤ºå‰10æ¡
        print(f"  ID: {record['id']:4d} | {record['filename'][:40]:40s} | "
              f"{record['pages']} é¡µ | æ¸…ç† {record['removed']} å­—ç¬¦")

    if len(records_to_clean) > 10:
        print(f"  ... è¿˜æœ‰ {len(records_to_clean) - 10} æ¡è®°å½• ...")

    print(f"\nğŸ’¡ æ€»è®¡å°†æ¸…ç† {total_removed} ä¸ªå­—ç¬¦çš„æ ‡ç­¾")
    print("\næç¤º: ä½¿ç”¨ --apply å‚æ•°æ‰§è¡Œæ¸…ç†, --backup å‚æ•°åŒæ—¶å¤‡ä»½æ•°æ®åº“\n")

    return True


def apply_cleaning(session, backup: bool = False):
    """æ‰§è¡Œæ¸…ç†"""
    # å¤‡ä»½æ•°æ®åº“
    if backup:
        db_path = str(settings.DATABASE_URL).replace('sqlite:///', '')
        if not backup_database(db_path):
            print("âŒ å¤‡ä»½å¤±è´¥ï¼Œå–æ¶ˆæ¸…ç†æ“ä½œ")
            return

    print("\n" + "=" * 60)
    print("æ‰§è¡Œæ¸…ç† - å¤„ç†ä¸­...")
    print("=" * 60 + "\n")

    # æŸ¥è¯¢æ‰€æœ‰æœ‰ OCR ç»“æœçš„è®°å½•
    histories = session.query(History).filter(
        History.ocr_result.isnot(None),
        History.ocr_result != ""
    ).all()

    total_records = 0
    total_removed = 0

    for history in histories:
        try:
            ocr_data = json.loads(history.ocr_result)

            # æ¸…ç†æ¯ä¸ªé¡µé¢çš„æ–‡æœ¬
            needs_update = False
            record_removed = 0

            for page in ocr_data:
                if 'text' in page:
                    cleaned_text, removed = clean_deepseek_tags(page['text'])
                    if removed > 0:
                        page['text'] = cleaned_text
                        needs_update = True
                        record_removed += removed

            # æ›´æ–°æ•°æ®åº“
            if needs_update:
                history.ocr_result = json.dumps(ocr_data, ensure_ascii=False)
                total_records += 1
                total_removed += record_removed

                print(f"  âœ“ ID {history.id:4d} | {history.original_filename[:40]:40s} | "
                      f"æ¸…ç†äº† {record_removed} å­—ç¬¦")

        except json.JSONDecodeError as e:
            print(f"  âœ— ID {history.id:4d} | JSON è§£æé”™è¯¯: {e}")
            continue

    # æäº¤æ›´æ”¹
    try:
        session.commit()
        print(f"\nâœ… æ¸…ç†å®Œæˆ!")
        print(f"   - å¤„ç†äº† {total_records} æ¡è®°å½•")
        print(f"   - æ€»è®¡æ¸…ç† {total_removed} ä¸ªå­—ç¬¦\n")
    except Exception as e:
        session.rollback()
        print(f"\nâŒ æäº¤å¤±è´¥: {e}\n")


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='æ¸…ç† OCR å†å²è®°å½•ä¸­çš„ DeepSeek-OCR åæ ‡æ ‡ç­¾',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python clean_ocr_tags.py              é¢„è§ˆéœ€è¦æ¸…ç†çš„è®°å½•
  python clean_ocr_tags.py --apply      æ‰§è¡Œæ¸…ç†
  python clean_ocr_tags.py --backup     æ‰§è¡Œæ¸…ç†å¹¶å¤‡ä»½æ•°æ®åº“
        """
    )

    parser.add_argument('--apply', action='store_true',
                       help='æ‰§è¡Œæ¸…ç†ï¼ˆé»˜è®¤åªé¢„è§ˆï¼‰')
    parser.add_argument('--backup', action='store_true',
                       help='æ¸…ç†å‰å¤‡ä»½æ•°æ®åº“')

    args = parser.parse_args()

    # åˆ›å»ºæ•°æ®åº“ä¼šè¯
    db_url = str(settings.DATABASE_URL)
    engine = create_engine(db_url)
    SessionLocal = sessionmaker(bind=engine)
    session = SessionLocal()

    try:
        if args.apply or args.backup:
            apply_cleaning(session, backup=args.backup)
        else:
            has_records = preview_cleaning(session)
            if not has_records:
                return 0
            return 1
    finally:
        session.close()

    return 0


if __name__ == "__main__":
    sys.exit(main())
